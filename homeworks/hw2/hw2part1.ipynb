{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HW2 part1\n",
        "\n",
        "Chen Jiaxin\n",
        "1155246854"
      ],
      "metadata": {
        "id": "TF52tV7OItRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step1 Install Required Packages"
      ],
      "metadata": {
        "id": "g1xQkQxRJYA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install markitdown[pdf]\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "oyqGaMnqJIXX",
        "outputId": "0c941997-e4d5-4303-db12-7201dabc950b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: markitdown[pdf] in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.6.3)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Requirement already satisfied: pdfminer-six>=20251230 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (20251230)\n",
            "Requirement already satisfied: pdfplumber>=0.11.9 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.11.9)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.24.2)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (5.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Requirement already satisfied: langchain_mcp_adapters in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (4.2.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step2 Import Libraries"
      ],
      "metadata": {
        "id": "_cpk2T6bJTVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from markitdown import MarkItDown\n",
        "import gdown"
      ],
      "metadata": {
        "id": "WJtu2GMTJcte"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step3 Set API Keys and MCP Client"
      ],
      "metadata": {
        "id": "LtOtGLo9Jf1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek-chat\",\n",
        "    api_key=DEEPSEEK_API_KEY,\n",
        "    base_url=\"https://api.deepseek.com/v1\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "-DtHNci5JlUi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step4  Download CV Files"
      ],
      "metadata": {
        "id": "CB6Z9IZfJqAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "MrMp85LyJu1Y",
        "outputId": "f0ab5637-696c-40f5-b4fb-d1be05347cbd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|██████████| 147k/147k [00:00<00:00, 4.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|██████████| 75.1k/75.1k [00:00<00:00, 3.98MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|██████████| 72.0k/72.0k [00:00<00:00, 3.85MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|██████████| 73.3k/73.3k [00:00<00:00, 3.47MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|██████████| 97.9k/97.9k [00:00<00:00, 4.13MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step5 Initialize MCP Client and Tools"
      ],
      "metadata": {
        "id": "G6uujFTjJzZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "mcp_tools = await client.get_tools()\n",
        "FACEBOOK_SEARCH = 0\n",
        "FACEBOOK_PROFILE = 1\n",
        "LINKEDIN_SEARCH = 3\n",
        "LINKEDIN_PROFILE = 4"
      ],
      "metadata": {
        "id": "qT4DtzLMJ202"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step6 Extract Information from CV\n",
        "\n",
        "We extract the key information from the CV, such as name, city, education, and experience, to facilitate comparison across multiple platforms later."
      ],
      "metadata": {
        "id": "7ESZeCm0J7FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_cv_info(cv_text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract structured information from this CV.\n",
        "    Return ONLY valid JSON.\n",
        "\n",
        "    Format:\n",
        "    {{\n",
        "        \"name\": \"\",\n",
        "        \"city\": \"\",\n",
        "        \"education\": [],\n",
        "        \"experience\": []\n",
        "    }}\n",
        "\n",
        "    CV:\n",
        "    {cv_text}\n",
        "    \"\"\"\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = response.content.strip()\n",
        "\n",
        "    try:\n",
        "        json_match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
        "        if json_match:\n",
        "            return json.loads(json_match.group(0))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return {\"name\": \"\", \"city\": \"\", \"education\": [], \"experience\": []}"
      ],
      "metadata": {
        "id": "lQp89Vo_KAV-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step7 LinkedIn Search (LLM Selects Best Match)\n",
        "\n",
        "In this process, first search for the 10 candidates that best match the relevant information based on keywords, and then let the LLM determine which one best meets the requirements."
      ],
      "metadata": {
        "id": "aV2p0kNAKdbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def search_linkedin(cv_info):\n",
        "    try:\n",
        "        city = cv_info.get(\"city\", \"\")\n",
        "        if \",\" in city:\n",
        "            city = city.split(\",\")[0].strip()\n",
        "        search_results = await mcp_tools[LINKEDIN_SEARCH].ainvoke({\n",
        "            \"q\": cv_info.get(\"name\", \"\"),\n",
        "            \"location\": city,\n",
        "            \"limit\": 10,\n",
        "            \"fuzzy\": True\n",
        "        })\n",
        "\n",
        "        if not search_results:\n",
        "            return None\n",
        "\n",
        "        linkedin_people = json.loads(search_results[0][\"text\"])\n",
        "        if not linkedin_people:\n",
        "            return None\n",
        "\n",
        "        selection_prompt = f\"\"\"\n",
        "        CV:\n",
        "        {json.dumps(cv_info, indent=2)}\n",
        "\n",
        "        Candidates:\n",
        "        {json.dumps(linkedin_people, indent=2)}\n",
        "\n",
        "        Select the BEST matching profile.\n",
        "        Return ONLY the profile id.\n",
        "        If none match, return NONE.\n",
        "        \"\"\"\n",
        "        response = llm.invoke([HumanMessage(content=selection_prompt)])\n",
        "        selected_id = response.content.strip()\n",
        "\n",
        "        if selected_id == \"NONE\":\n",
        "            return None\n",
        "\n",
        "        selected_id = int(re.search(r\"\\d+\", selected_id).group())\n",
        "\n",
        "        profile_result = await mcp_tools[LINKEDIN_PROFILE].ainvoke({\n",
        "            \"person_id\": selected_id\n",
        "        })\n",
        "\n",
        "        return json.loads(profile_result[0][\"text\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"LinkedIn error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "5Y1oj73oKkB3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step8 Facebook Search (LLM Selects Best Match)\n",
        "\n",
        "The same as the step7.first search for the 10 candidates from Facebook that best match the relevant information based on keywords, and then let the LLM determine which one best meets the requirements."
      ],
      "metadata": {
        "id": "PDxnq5D_Lc00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def search_facebook(cv_info):\n",
        "    try:\n",
        "        search_results = await mcp_tools[FACEBOOK_SEARCH].ainvoke({\n",
        "            \"q\": cv_info.get(\"name\", \"\"),\n",
        "            \"limit\": 10,\n",
        "            \"fuzzy\": True\n",
        "        })\n",
        "\n",
        "        if not search_results:\n",
        "            return None\n",
        "\n",
        "        fb_users = json.loads(search_results[0][\"text\"])\n",
        "        if not fb_users:\n",
        "            return None\n",
        "\n",
        "        selection_prompt = f\"\"\"\n",
        "        CV:\n",
        "        {json.dumps(cv_info, indent=2)}\n",
        "\n",
        "        Facebook Candidates:\n",
        "        {json.dumps(fb_users, indent=2)}\n",
        "\n",
        "        Select BEST match.\n",
        "        Return ONLY user_id.\n",
        "        If none match, return NONE.\n",
        "        \"\"\"\n",
        "\n",
        "        response = llm.invoke([HumanMessage(content=selection_prompt)])\n",
        "        selected_id = response.content.strip()\n",
        "\n",
        "        if selected_id == \"NONE\":\n",
        "            return None\n",
        "\n",
        "        selected_id = int(re.search(r\"\\d+\", selected_id).group())\n",
        "\n",
        "        profile_result = await mcp_tools[FACEBOOK_PROFILE].ainvoke({\n",
        "            \"user_id\": selected_id\n",
        "        })\n",
        "        return json.loads(profile_result[0][\"text\"])\n",
        "    except Exception as e:\n",
        "        print(\"Facebook error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "CcAf68o3Liha"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step9 LLM Verification Decision\n",
        "\n",
        "Based on all the information obtained earlier, the LLM evaluates the identity consistency between the CV and its corresponding LinkedIn and Facebook profiles. First, the model is instructed to score and provide explanations across four dimensions: name, education background, work experience, and geographic location (each dimension scored 0–1). The JSON results returned by the model are then parsed. A weighted average is calculated based on my designed weights (\"name_score\": 0.25, \"education_score\": 0.35, \"experience_score\": 0.25, \"location_score\": 0.15) across the four dimensions to derive a final comprehensive matching score (constrained between 0–1). If parsing fails, a default value of 0 is returned."
      ],
      "metadata": {
        "id": "glc-660lLxMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_verification_decision(cv_info, linkedin_profile, facebook_profile):\n",
        "    prompt = f\"\"\"\n",
        "You are a strict KYC identity verification system.\n",
        "\n",
        "Compare the CV with LinkedIn and Facebook profiles.\n",
        "\n",
        "CV:\n",
        "{json.dumps(cv_info, indent=2)}\n",
        "\n",
        "LinkedIn:\n",
        "{json.dumps(linkedin_profile, indent=2) if linkedin_profile else \"Not Found\"}\n",
        "\n",
        "Facebook:\n",
        "{json.dumps(facebook_profile, indent=2) if facebook_profile else \"Not Found\"}\n",
        "----------------------------------\n",
        "TASK:\n",
        "\n",
        "Evaluate identity consistency across:\n",
        "\n",
        "1. Name consistency\n",
        "2. Education consistency\n",
        "3. Experience / Company consistency\n",
        "4. City / Location consistency\n",
        "\n",
        "Scoring Rules:\n",
        "- 1.0 = fully consistent\n",
        "- 0.0 = completely inconsistent\n",
        "- Intermediate values allowed\n",
        "- Missing LinkedIn should NOT be penalized\n",
        "- If LinkedIn not found but Facebook matches name and location,\n",
        "  treat as weak positive evidence\n",
        "- Facebook job mismatch alone should not cause very low experience_score\n",
        "- If company completely mismatches → experience_score must be low\n",
        "- If education totally different → education_score must be low\n",
        "- If names differ significantly → name_score must be low\n",
        "- Missing Facebook is NOT heavily penalized\n",
        "\n",
        "----------------------------------\n",
        "\n",
        "Return ONLY valid JSON in this format:\n",
        "\n",
        "{{\n",
        "  \"name_score\": 0-1,\n",
        "  \"education_score\": 0-1,\n",
        "  \"experience_score\": 0-1,\n",
        "  \"location_score\": 0-1,\n",
        "  \"reason\": \"short explanation\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = response.content.strip()\n",
        "\n",
        "    try:\n",
        "        json_match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
        "        if not json_match:\n",
        "            return 0\n",
        "\n",
        "        result = json.loads(json_match.group(0))\n",
        "\n",
        "        weights = {\n",
        "            \"name_score\": 0.25,\n",
        "            \"education_score\": 0.35,\n",
        "            \"experience_score\": 0.25,\n",
        "            \"location_score\": 0.15\n",
        "        }\n",
        "\n",
        "        final_score = 0\n",
        "        for key, weight in weights.items():\n",
        "            score_value = result.get(key, 0)\n",
        "            try:\n",
        "                score_value = float(score_value)\n",
        "            except:\n",
        "                score_value = 0\n",
        "            final_score += score_value * weight\n",
        "\n",
        "        final_score = max(0.0, min(1.0, final_score))\n",
        "\n",
        "        return final_score\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Score parse error:\", e)\n",
        "        return 0"
      ],
      "metadata": {
        "id": "DUAbQVtyL4uQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step10 Main Processing Function\n",
        "\n",
        "The main purpose of this step is to batch process all PDF resumes. It iterates through all PDF files in the specified directory, reads and parses each one into text, extracts structured CV information, then searches for corresponding profiles on LinkedIn and Facebook respectively, prints debugging information, and finally calls the previously defined LLM scoring function to calculate identity matching scores, storing each resume's final score in a list for return.If no relevant information can be found on either platform, select the most similar ones and re-evaluate."
      ],
      "metadata": {
        "id": "uvE6CtE5NQdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def process_all_cvs():\n",
        "    md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "    pdf_files = sorted(\n",
        "        [f for f in os.listdir(output_dir) if f.lower().endswith(\".pdf\")],\n",
        "        key=lambda x: int(\"\".join(filter(str.isdigit, x)) or \"0\")\n",
        "    )\n",
        "    scores = []\n",
        "    for pdf_name in pdf_files:\n",
        "        print(f\"\\nProcessing {pdf_name}\")\n",
        "        pdf_path = os.path.join(output_dir, pdf_name)\n",
        "        result = md.convert(pdf_path)\n",
        "        cv_info = extract_cv_info(result.text_content)\n",
        "        linkedin_profile = await search_linkedin(cv_info)\n",
        "        facebook_profile = await search_facebook(cv_info)\n",
        "        print(\"LinkedIn Profile Found:\", linkedin_profile is not None)\n",
        "        print(\"Facebook Profile Found:\", facebook_profile is not None)\n",
        "        if linkedin_profile is None and facebook_profile is None:\n",
        "            print(\"Both platforms failed. Re-running search to force best match...\")\n",
        "\n",
        "            linkedin_profile = await search_linkedin(cv_info)\n",
        "            facebook_profile = await search_facebook(cv_info)\n",
        "\n",
        "        decision = llm_verification_decision(\n",
        "            cv_info,\n",
        "            linkedin_profile,\n",
        "            facebook_profile\n",
        "        )\n",
        "\n",
        "        scores.append(decision)\n",
        "        print(\"Decision:\", decision)\n",
        "    return scores\n",
        "scores = await process_all_cvs()\n",
        "print(\"\\nFINAL SCORES:\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "baVRMv_FZojd",
        "outputId": "c903dd32-507a-4238-ba2d-5a5a36fb29f3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing CV_1.pdf\n",
            "LinkedIn Profile Found: False\n",
            "Facebook Profile Found: True\n",
            "Decision: 0.5549999999999999\n",
            "\n",
            "Processing CV_2.pdf\n",
            "LinkedIn Profile Found: True\n",
            "Facebook Profile Found: True\n",
            "Decision: 0.875\n",
            "\n",
            "Processing CV_3.pdf\n",
            "LinkedIn Profile Found: False\n",
            "Facebook Profile Found: True\n",
            "Decision: 0.73\n",
            "\n",
            "Processing CV_4.pdf\n",
            "LinkedIn Profile Found: False\n",
            "Facebook Profile Found: False\n",
            "Both platforms failed. Re-running search to force best match...\n",
            "Decision: 0.0\n",
            "\n",
            "Processing CV_5.pdf\n",
            "LinkedIn Profile Found: True\n",
            "Facebook Profile Found: True\n",
            "Decision: 0.42500000000000004\n",
            "\n",
            "FINAL SCORES: [0.5549999999999999, 0.875, 0.73, 0.0, 0.42500000000000004]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step11 Evaluation Code"
      ],
      "metadata": {
        "id": "JgLA4IlpN3NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n",
        "groundtruth = [1, 1, 1, 0, 0]\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(\"Evaluation Result:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IEPixy0KOJuo",
        "outputId": "7d1fbb91-a861-467b-870a-ceb430c5f715"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Result:\n",
            "{'decisions': [1, 1, 1, 0, 0], 'correct': 5, 'total': 5, 'final_score': 1.0}\n"
          ]
        }
      ]
    }
  ]
}